[
  {
    "id": 1,
    "data": "2025-01-17T14:30:15.000Z",
    "title": "Instagram ganha feed somente com Reels curtidos por amigos",
    "image": "",
    "message": "O Instagram terá um novo feed de Reels somente com publicações curtidas por amigos, anunciou o chefe da rede social, Adam Mosseri, nesta sexta-feira (17). A novidade busca tornar o consumo de conteúdo uma atividade mais ativa.\r\n\r\n'Queremos que o Instagram não seja somente um lugar que você consome conteúdo divertido, mas também um lugar que você conecta com amigos usando esse conteúdo', disse o executivo.\r\n\r\nConforme descreve o líder da plataforma, será incluído um feed de Reels somente com conteúdo curtido ou com notas de amigos. Ele estará acessível a partir do canto superior direito da tela.\r\n\r\nO Instagram sempre exibiu curtidas de perfis seguidos em Reels exibidos no feed — eles aparecem no topo da lista ao abrir a seção 'Curtidas' de uma publicação, por exemplo. Contudo, a plataforma passou a dar ainda mais destaque às interações quando adicionou as notas ou as curtidas flutuantes, que destacam as curtidas de alguns perfis seguidos.\r\n\r\nPorém, essa é a primeira vez que o Instagram inclui um feed de Reels inteiramente composto por publicações curtidas por perfis seguidos. Nesta área, é garantido que pelo menos uma pessoa seguida interagiu com a publicação, diferente do algoritmo tradicional.\r\n\r\nDedo-duro de curtidas no Instagram\r\n\r\nPara quem está no Instagram, a novidade deve lembrar a antiga área 'Seguindo', abandonada em outubro de 2019. A seção mostrava a atividade de todos os perfis seguidos na rede social, incluindo curtidas e novos follows — era um 'dedo-duro' da rede social.\r\n\r\nNão está claro como o Instagram vai balancear o novo feed de Reels com a privacidade de usuários e, de certa forma, a novidade pode coibir curtidas e interações com publicações da plataforma — especialmente quando tangem opiniões ou temas polêmicos, por exemplo.\r\n\r\nFonte: https://www.techtudo.com.br/noticias/2024/11/instagram-ganha-feed-somente-com-reels-curtidos-por-amigos.ghtml",
    "createdAt": "2025-01-17T14:30:15.000Z",
    "updatedAt": "2025-01-17T14:30:15.000Z"
  },
  {
    "id": 2,
    "data": "2025-01-17T14:13:34.000Z",
    "title": "Hackers da China teriam invadido mais de 400 PCs do governo dos EUA",
    "image": "",
    "message": "Um ciberataque orquestrado por invasores ligados ao governo da China teria acessado uma série de computadores do Departamento do Tesouro dos Estados Unidos. De acordo com a Bloomberg, o equivalente ao Ministério da Fazenda do país foi mesmo alvo de espionagem e teve vários dados roubados.\r\n\r\nO próprio governo já havia anunciado a descoberta do acesso indevido, mas só agora maiores detalhes foram divulgados. De acordo com a documentação enviada ao Congresso dos EUA, 'mais de 400 notebooks e desktops' foram acessados indevidamente por terceiros.\r\n\r\nA maior parte dos aparelhos seria de funcionários ligados a temas como sanções, assuntos internacionais e inteligência.\r\n\r\nJá os arquivos possivelmente acessados incluem logins e senhas, documentos de viagem ou planejamento estratégico e materiais sobre sanções e investimentos no estrangeiro. Emails e certos dados confidenciais, porém, não chegaram a ser comprometidos.\r\n\r\nComo foi o ataque?\r\n\r\nSegundo o relatório, não há evidência de que algum malware foi usado para ganhar acesso aos sistemas e nem que informações foram acessadas a longo prazo — o ataque foi pontual e feito a partir de meios ainda não conhecidos, mas que provavelmente envolveram engenharia social e uso de credenciais válidas.\r\n\r\nEm novembro de 2024, os EUA confirmaram ainda a invasão de cibercriminosos também supostamente contratados pela China em redes de telecomunicações. No período, o FBI até chegou a sugerir o uso de aplicativos criptografados para troca de mensagens por quem não quisesse correr o risco de ser espionado.\r\n\r\nUm mês depois, o governo foi informado pela terceirizada BeyondTrust que as redes do Departamento do Tesouro foram invadidas. O grupo Silk Typhoon, responsável pela invasão de novembro, teria agido junto de grupos como o UNC5221 entre os meses de setembro e novembro.\r\n\r\nO que diz a China?\r\n\r\nApós a detecção da invasão, todos os sistemas da companhia foram desligados e uma nova empresa deve ser contratada no lugar.\r\n\r\nOs funcionários afetados já foram notificados e relatórios mais completos sobre os possíveis danos causados à rede ainda não foram finalizados.\r\n\r\nEm resposta, a embaixada da China na região nega a ligação com o ataque e diz que os EUA 'precisa parar de usar cibersegurança para manchar e caluniar' o país, além de 'parar de espalhar todo tipo de desinformação sobre a suposta ameaça hacker chinesa'.\r\n\r\nFonte: https://www.https://www.tecmundo.com.br/seguranca/401640-hackers-da-china-teriam-invadido-mais-de-400-pcs-do-governo-dos-eua.htm",
    "createdAt": "2025-01-17T13:34:15.000Z",
    "updatedAt": "2025-01-17T13:34:15.000Z"
  },
  {
    "id": 3,
    "data": "2025-01-17T11:50:34.000Z",
    "title": "Google não vai respeitar futura lei de verificação de fatos da Europa",
    "image": "https://tm.ibxk.com.br/2025/01/17/17112440678272.jpg?ims=1280x480",
    "message": "O Google não vai cumprir uma futura legislação de verificação de informações da União Europeia, anunciou a empresa em carta obtida pela Axios. O regulamento exige que a Gigante das Buscas incorpore checagem de notícias falsas no buscador e no YouTube.\r\n\r\nA exigência da Comissão Europeia é parte do novo Código de Prática sobre Desinformação. Quando inaugurado em 2018, o regulamento estabelecia padrões para o tratamento de informações somente para empresas voluntárias, mas se tornará obrigatório em breve.\r\n\r\nO novo código de prática europeu requer que as plataformas adicionem 'uso mais consistente de verificação de fatos em seus serviços'. No caso do Google, isso aconteceria com a implementação de verificação de fatos na busca e no YouTube, bem como mudanças no algoritmo de ranqueamento de resultados.\r\n\r\nNo comunicado, o presidente de assuntos globais do Google, Kent Walker, disse que a inclusão de verificação de fatos 'simplesmente não é apropriada ou efetiva' para os serviços da companhia.\r\n\r\nComo prova, Walker ressaltou o bom resultado da moderação de conteúdo do Google durante o 'ciclo sem precedentes de eleições' de 2024. Além disso, o executivo também mencionou que as notas contextuais da plataforma de vídeos tem 'potencial significativo'.\r\n\r\nAinda no texto, o executivo do Google afirma que a empresa continuará trabalhando em tecnologias de moderação de conteúdo como Synth ID e avisos de uso de IA em vídeos no YouTube.\r\n\r\nAté agora, o Google não se manifestou sobre o comunicado. Por enquanto, não se sabe como a União Europeia vai agir perante o descumprimento da legislação.\r\n\r\nFonte: https://www.tecmundo.com.br/internet/401633-google-nao-vai-respeitar-futura-lei-de-verificacao-de-fatos-da-europa.htm",
    "createdAt": "2025-01-17T11:50:15.000Z",
    "updatedAt": "2025-01-17T11:50:15.000Z"
  },
  {
    "id": 4,
    "data": "2025-01-16T16:14:34.000Z",
    "title": "NVIDIA lança microsserviços NIM para proteger aplicações com agentes de IA",
    "image": "https://www.adrenaline.com.br/wp-content/uploads/2025/01/Captura-de-tela-2025-01-16-160903.webp",
    "message": "A NVIDIA lançou os novos microsserviços NIM, um conjunto de soluções avançadas projetadas para proteger e escalar agentes de IA generativa.\r\n\r\nIntegrados à plataforma NeMo Guardrails, essas ferramentas são voltadas para segurança, confiabilidade e controle em aplicações de IA em setores como varejo, saúde e automotivo.\r\n\r\nO que são os NeMo Guardrails e como funcionam?\r\n\r\nOs NeMo Guardrails são uma coleção de ferramentas e políticas que atuam como “barreiras de proteção” para agentes de IA. Eles asseguram que os modelos de IA se comportem de forma controlada e segura, limitando respostas inadequadas, enviesadas ou que fujam de contextos predefinidos.\r\n\r\nNo total, são três novos microsserviços:\r\n\r\nSegurança de conteúdo: evita resultados prejudiciais ou não éticos.\r\n\r\nControle de tópicos: restringe a conversa a temas aprovados.\r\n\r\nProteção contra jailbreak: impede tentativas de burlar as restrições do sistema.\r\n\r\nSão eles que orquestram as interações de IA para atender às diretrizes da empresa e aumentar a confiança do usuário. Todos os recursos foram desenvolvidos para permitir que agentes de IA operem em grande escala, com baixa latência e eficiência mesmo em ambientes limitados.\r\n\r\nAqui estão alguns exemplos práticos de suas aplicações:\r\n\r\nAtendimento ao cliente no varejo: imagine um assistente virtual em uma loja online ajudando clientes a encontrar produtos específicos. O Controle de tópicos evita que o assistente desvie a conversa para temas irrelevantes, enquanto a Segurança de conteúdo assegura respostas educadas e precisas.\r\n\r\nAssistentes automotivos inteligentes: em um carro conectado, um assistente de voz pode informar rotas, controlar funções do veículo e responder a dúvidas do motorista. Com os guardrails, ele evita sugestões inadequadas, como rotas perigosas ou comandos fora de contexto, garantindo interações seguras e úteis.\r\n\r\nSaúde e consultas médicas: um chatbot de suporte médico pode oferecer informações básicas sobre sintomas ou medicamentos. O NeMo Guardrails ajuda a limitar a conversa a informações gerais, orientando o paciente a buscar um profissional para casos mais complexos, evitando diagnósticos automáticos.\r\n\r\nPrevenção de fraudes em bancos: um agente virtual em uma instituição financeira pode verificar transações e dar suporte aos clientes. A Detecção de jailbreak impede que criminosos manipulem o sistema para acessar informações confidenciais, protegendo a integridade dos dados.\r\n\r\nSuporte técnico em tecnologia: no setor de TI, assistentes de IA podem solucionar problemas comuns de usuários. Os guardrails garantem que respostas sejam técnicas e úteis, evitando conteúdos irrelevantes ou inadequados.\r\n\r\nCasos de uso e parcerias\r\n\r\nGrandes players, como Amdocs e Cerence AI, utilizam o NeMo Guardrails para criar assistentes confiáveis. No varejo, o AI Blueprint da NVIDIA ajuda empresas como a Lowe’s a capacitar equipes e melhorar a experiência dos clientes.\r\n\r\nO ActiveScore, da ActiveFence, reforça a segurança de conteúdo em tempo real. A adoção também está avançando com o AI Blueprint, solução da NVIDIA para assistentes de compras no varejo, que integra os guardrails para reforçar a confiança no atendimento digital.\r\n\r\nAlém disso, para acelerar ainda mais a adoção de proteções de IA no desenvolvimento e implantação de aplicações de IA no varejo, a NVIDIA anunciou recentemente na feira NRF que seu NVIDIA AI Blueprint para assistentes de compras no varejo incorpora os microsserviços NeMo Guardrails para criar interações mais confiáveis e controladas com os clientes durante as experiências de compras digitais.\r\n\r\nOs líderes de consultoria Taskus, Tech Mahindra e Wipro também estão integrando o NeMo Guardrails em suas soluções para fornecer aos seus clientes corporativos aplicações de IA geradoras mais seguras, confiáveis e controladas.\r\n\r\nO Hive, que fornece seus modelos de detecção de conteúdo gerados por IA para imagens, vídeo e conteúdo de áudio como microsserviços NIM, pode ser facilmente integrado e orquestrado em aplicações de IA usando o NeMo Guardrails.\r\n\r\nResumindo, líderes do setor estão utilizando os NeMo Guardrails para personalizar e proteger suas soluções de IA:\r\n\r\nAmdocs: está aprimorando suas interações com clientes usando agentes de IA confiáveis.\r\nCerence AI: utiliza os guardrails em assistentes automotivos, garantindo interações seguras e conscientes.\r\nLowe’s: emprega a tecnologia para capacitar funcionários no atendimento ao cliente com IA generativa segura e precisa.\r\n\r\nPor que o NeMo Guardrails é útil?\r\n\r\nCom a rápida expansão da IA em diferentes setores, problemas como alucinações de resposta, vazamento de dados e falta de contextualização têm se tornado desafiadores. O NeMo Guardrails traz ferramentas práticas para abordar essas questões, com suporte de código aberto para fácil integração.\r\n\r\nAlém disso, os desenvolvedores têm acesso ao Garak, uma solução de código-aberto que identifica vulnerabilidades em modelos LLM, como problemas de segurança ou cenários adversos. Documentação e tutoriais completos estão disponíveis para maximizar o uso dessas ferramentas.\r\n\r\nFonte: https://www.adrenaline.com.br/nvidia/nvidia-lanca-microsservicos-nim-agente-ia/",
    "createdAt": "2025-01-16T16:14:34.000Z",
    "updatedAt": "2025-01-16T16:14:34.000Z"
  },
  {
    "id": 5,
    "data": "2025-01-18T07:00:34.000Z",
    "title": "A busca pela longevidade com inteligência artificial - The BRIEF 18/01",
    "image": "",
    "message": "Impacto nos criadores\r\n\r\nCom a proibição do TikTok nos EUA prevista para domingo, influenciadores como Sarah Perl (@hothighpriestess, 2,5 milhões de seguidores) e pequenos negócios enfrentam uma possível interrupção de receita significativa. \r\n\r\nNo entanto, o impacto da medida vai além dos grandes nomes. Segundo Jess Maddox, pesquisadora de redes sociais, os mais prejudicados serão microinfluenciadores e pequenas empresas que dependem da plataforma para vendas e exposição. \r\n\r\nApesar do cenário incerto, influenciadores mostram resiliência. Alguns, como Perl, veem a oportunidade de explorar novas plataformas, enquanto outros planejam expandir sua presença em redes existentes. Para criadores e negócios, a lição parece clara: adaptação será a chave para sobreviver em um ecossistema digital em constante mudança.\r\n\r\nMicrosoft intensifica aposta na IA \r\n\r\nA Microsoft deu mais um passo ambicioso em direção à liderança no mercado de inteligência artificial. A criação do grupo de engenharia CoreAI – Platform and Tools, liderado por Jay Parikh, ex-chefe de engenharia da Meta, consolida a fusão entre suas divisões de desenvolvimento e IA. \r\n\r\nA ideia é transformar o conceito de “software como serviço” em “serviço como software,” automatizando tarefas humanas com IA. Para Satya Nadella, CEO da Microsoft, essa mudança promete “redefinir todas as categorias de aplicativos”, reforçando o foco em soluções como Copilot e a integração de IA em ferramentas como Word e Excel.\r\n\r\nO relançamento do Microsoft 365 Copilot Chat também evidencia a estratégia da empresa de tornar a IA indispensável no ambiente corporativo. Com recursos gratuitos de chatbot e agentes pagos sob demanda, a Microsoft busca fidelizar empresas ao oferecer ferramentas que vão desde análises no Excel até resumos automáticos no Teams. No entanto, a aceitação da IA nos negócios ainda é um desafio, especialmente com a concorrência do Google, que recentemente tornou gratuitas as funcionalidades de IA no Google Workspace, aumentando a pressão sobre a gigante de Redmond.\r\n\r\nCiência da longevidade\r\n\r\nFalando em IA, a OpenAI revelou o GPT-4b micro, seu primeiro modelo voltado à biologia, desenvolvido em colaboração com a Retro Biosciences - não por acaso, uma startup financiada pelo CEO da empresa, Sam Altman. O modelo foi treinado para reengenharia de proteínas, como os fatores Yamanaka, que transformam células da pele em células-tronco jovens. \r\n\r\nA parceria busca soluções para prolongar a vida humana em até 10 anos, explorando a possibilidade de regeneração de tecidos e produção de órgãos humanos. Os resultados iniciais são promissores: o GPT-4b micro projetou versões mais eficientes dessas proteínas, aumentando sua eficácia em mais de 50%. Apesar de ainda não ser um produto comercial, a OpenAI acredita que a abordagem pode revolucionar áreas como regeneração celular e biotecnologia. \r\n\r\nA colaboração, no entanto, levanta questões sobre possíveis conflitos de interesse envolvendo os múltiplos investimentos de Altman. Apesar disso, a OpenAI afirma que o trabalho científico é independente de decisões financeiras.  \r\n\r\nFonte: https://www.tecmundo.com.br/mercado/401647-a-busca-pela-longevidade-com-inteligencia-artificial---the-brief-1801.htm",
    "createdAt": "2025-01-18T07:00:34.000Z",
    "updatedAt": "2025-01-18T07:00:34.000Z"
  },
  {
    "id": 6,
    "data": "2025-02-06T07:15:41.000Z",
    "title": "Gemini 2.0 Pro: o que é e como testar IA mais avançada do Google",
    "image": "https://s2-techtudo.glbimg.com/VUKJCYlNOe6JbYIS0FSfDFRPuz4=/0x0:1119x652/1000x0/smart/filters:strip_icc()/i.s3.glbimg.com/v1/AUTH_08fbf48bc0524877943fe86e43087e7a/internal_photos/bs/2024/M/6/bowOCaRJuIJp61LybpFw/image-24-.png",
    "message": "Gemini 2.0 Pro tem janela de contexto com suporte a mais de 1,5 milhão de palavras, interface com apps Google e mais “conhecimento de mundo”; saiba mais e veja como testar\r\n\r\nO Gemini 2.0 Pro, modelo mais avançado de inteligência artificial (IA) do Google foi liberado para testes na quarta-feira (5). A novidade tem uma série de inovações em relação à versão 1.5 Pro, como uma janela de contexto de 2 milhões de tokens — aproximadamente 1,5 milhão de palavras —, e interação direta com diversos aplicativos Google, como YouTube, e buscas. O lançamento já está disponível para assinantes do serviço Gemini Advanced, mas também pode ser testado de graça nas plataformas Google AI Studio e Vertex AI, mais voltadas para desenvolvedores. O TechTudo já testou algumas das novas funcionalidades. A seguir, confira mais informações sobre o Gemini 2.0 Pro e como usar. \r\n\r\nDiferenças entre Gemini 2.0 Pro e modelos anteriores\r\n\r\nApós o lançamento do DeepSeek, a comunidade tech ficou assombrada com como um modelo com orçamento tão reduzido exibia toda a lógica de execução, enquanto os modelos bilionários do Google e OpenAI escondiam isso, algo que sempre levantou questões sobre a transparência sobre o funcionamento das IAs.\r\n\r\nO Gemini Google introduziu a funcionalidade de exibir o raciocínio neste novo modelo, e ela já está disponível nas opções 2.0 Flash Thinking experimentais, mas não está claro se ela irá chegar também ao Gemini 2.0 Pro. Isso porque, segundo a publicação oficial da empresa, o foco do modelo mais robusto está na execução de prompts complexos e desempenho de codificação elevado.\r\n\r\nNo entanto, isso não significa que o modelo não tenha uma capacidade elevada de raciocínio — superior à dos modelos Flash, conforme os testes internos do Google — mas apenas que a funcionalidade de exibir este caminho não deve ser implementada, ao menos em um primeiro momento. Apesar de não ter entrado em detalhes, uma justificativa seria liberar recursos computacionais para direcionar o máximo de desempenho para a execução das tarefas em si.\r\n\r\nOutro diferencial ainda mais importante para os novos modelos Gemini, este, sim, que chegará também à versão final do Gemini 2.0 Pro, é a capacidade de se conectar a ferramentas externas, como o Google Search, Lens, Google Maps, YouTube, e até a execução direta de códigos. Com isso, com a implementação adequada, desenvolvedores poderão solicitar que a IA não apenas gere códigos, como realize testes de aplicabilidade, por exemplo, para identificar funções que poderiam ser implementadas para melhorar a experiência final do usuário.\r\n\r\nNaturalmente, o suporte nativo a prompts multimodais introduzido nos modelos 2.0 Flash também está presente no Gemini 2.0 Pro, com suporte a upload de arquivos de até 7 MB, links para arquivos em repositórios web abertos, links do YouTube you acesso direto ao Google Drive. Contudo, o maior trunfo do modelo Pro é a janela de contexto de 2 milhões de tokens —aproximadamente 1,5 milhão de palavras —, o que permitiria criar um prompt com quase três vezes a trilogia de O Senhor dos Anéis, possibilitando submeter comandos com milhares de parâmetros e ainda obter um resultado excelente. \r\n\r\nComo testar o Gemini 2.0 Pro\r\n\r\nO Gemini 2.0 Pro está disponível em versão experimental (build de 05-02-2025) para desenvolvedores e usuários avançados por meio do Google AI Studio, Vertex AI, e para assinantes do serviço Gemini Advanced, tanto na versão desktop quanto mobile. É importante ressaltar, no entanto, que a versão de testes ainda não tem acesso a informações em tempo real, e trabalha exclusivamente com os dados utilizados no treinamento original do modelo. \r\n\r\nOutro detalhe relevante é que, apesar de se tratar do mesmo modelo, cada plataforma oferece diferentes níveis de configurações de profundidade, resultando em respostas diferentes para um mesmo prompt. Ao solicitar a criação de um roteiro minutado para um vídeo de 30 minutos comparando os smartphones Galaxy S24 e S25, o Gemini Advanced foi competente, mas bem mais conciso que o Google AI Studio que, por sua vez, gerou metade dos tokens de saída do Vertex AI.\r\n\r\n Passo 1. Acesse o site do Google AI Studio (https://aistudio.google.com/)\r\n\r\nPasso 2. Realize o login na plataforma utilizando uma conta Google \r\n\r\nPasso 3. Escolha o modelo Gemini 2.0 Pro Experimental 02-05 \r\n\r\nPasso 4. Digite seu prompt na janela de contexto e aguarde o resultado \r\n\r\nTestando no Vertex AI: \r\n\r\nPasso 1. Acesse a página de teste gratuito de 90 dias do Vertex AI (https://console.cloud.google.com/freetrial?redirectPath=/vertex-ai/studio) \r\n\r\nPasso 2. O link irá forçar automaticamente o direcionamento para tela de seleção de conta Google Cloud. Realize o login utilizando uma conta Google e aceite os termos do teste \r\n\r\nPasso 3. Clique em “Open Chat” (Abrir Chat) \r\n\r\nPasso 4. Escolha o modelo Gemini 2.0 Pro Experimental 02-05 \r\n\r\nPasso 5. Digite seu prompt na janela de contexto e aguarde o resultado \r\n\r\nTestando no Gemini Advanced \r\n\r\nPara os assinantes do serviço Gemini Advanced, é possível testar o Gemini 2.0 Pro simplesmente selecionando o modelo no botão localizado no canto superior esquerdo da interface. Apesar de a experiência em termos de estrutura textual ser satisfatória, por ainda ser experimental e não ter acesso a informações em tempo real, o resultado prático de pesquisas e referências do Gemini 1.5 Pro with Deep Research ainda é muito superior e complexo. \r\n\r\nCom o prompt modelo do comparativo entre os Galaxy S topo de linha, o Gemini anterior não apenas identificou que o aparelho foi anunciado oficialmente, como listou as especificações técnicas e criou tabelas comparativas, enquanto o Gemini 2.0 Pro apenas tratou o smartphone como um projeto futuro da Samsung. \r\n\r\nFonte: https://www.techtudo.com.br/dicas-e-tutoriais/2025/02/gemini-20-pro-o-que-e-e-como-testar-ia-mais-avancada-do-google-edsoftwares.ghtml",
    "createdAt": "2025-02-06T07:15:41.000Z",
    "updatedAt": "2025-02-06T07:15:41.000Z"
  },
  {
    "id": 7,
    "data": "2025-02-06T07:12:21.000Z",
    "title": "Malware encontrado em apps do iPhone pode ler capturas de tela; entenda",
    "image": "https://s2-techtudo.glbimg.com/tgV_Nzd6SqWsdp0ovbM5iA0k5to=/0x0:2022x1264/888x0/smart/filters:strip_icc()/i.s3.glbimg.com/v1/AUTH_08fbf48bc0524877943fe86e43087e7a/internal_photos/bs/2022/v/6/1nij2OQPuyFBeCgCVW1g/istock-936338884-e1626902959770.jpg",
    "message": "Impacto nos criadores\r\n\r\nVírus espião busca por palavras-chave em capturas de tela salvas na galeria de imagem do iPhone e repassa informações sensíveis para invasores; saiba mais sobre o malware \r\n\r\nPesquisadores da Kaspersky divulgaram, nesta quarta-feira (5), um estudo que revela a descoberta de um malware capaz de ler capturas de tela em aplicativos para iPhone. O spyware utiliza tecnologia de OCR para identificar palavras-chave relacionadas a carteiras de criptomoedas e enviá-las aos invasores, facilitando o roubo de bitcoins. De acordo com o estudo, apps como WeTink, AnyGPT, ComeCome e outros, todos disponíveis na App Store, estão infectados. No entanto, os pesquisadores afirmam não saber se a infecção é resultado de 'uma ação deliberada dos desenvolvedores' ou se foi causada por um ataque de terceiros. \r\n\r\nChamado de 'SparkCat' pelos pesquisadores da Kaspersky, o malware que afetou aplicativos do iPhone está ativo desde março de 2024. A mesma ameaça já havia sido identificada no ano passado em dispositivos Android e PCs. \r\n\r\n 'O módulo de malware para Android descriptografava e executava um plug-in de OCR criado com a biblioteca ML Kit do Google, utilizando-o para reconhecer textos em imagens armazenadas na galeria. Imagens que continham palavras-chave recebidas do servidor C2 eram enviadas para o atacante. O módulo malicioso específico para iOS tinha um design semelhante e também utilizava a biblioteca ML Kit do Google para OCR.', explicam os pesquisadores Dmitry Kalinin e Sergey Puzan. \r\n\r\nAo baixar e instalar um aplicativo infectado com o SparkCat, o usuário precisa conceder várias permissões ao software, incluindo acesso à galeria de imagens. Com essa autorização, o spyware entra em ação. A dupla de pesquisadores da Kaspersky também destaca a flexibilidade do malware, que pode ser usado para roubar outros dados capturados em screenshots, como senhas e informações bancárias. \r\n\r\n'Não podemos confirmar com certeza se a infecção foi resultado de um ataque à cadeia de suprimentos ou ação deliberada dos desenvolvedores. Alguns dos aplicativos, como serviços de entrega de comida, pareciam ser legítimos, enquanto outros aparentemente foram criados para atrair vítimas.', escreveram Kalinin e Puzan \r\n\r\nEmbora o estudo aponte uma lista extensa de aplicativos infectados, o público alvo do ataque do spyware está concentrado na Ásia e na Europa. Para evitar qualquer risco de acesso e roubo de informações, os pesquisadores da Kaspersky recomendam que os usuários de iPhone (e Android) evitem armazenar nos dispositivos capturas de telas que contenham informações sensíveis. \r\n\r\nFonte: https://www.techtudo.com.br/noticias/2025/02/malware-encontrado-em-apps-do-iphone-pode-ler-capturas-de-tela-entenda-edapps.ghtml",
    "createdAt": "2025-02-06T07:12:21.000Z",
    "updatedAt": "2025-02-06T07:12:21.000Z"
  },
  {
    "id": 8,
    "data": "2025-02-06T09:53:21.000Z",
    "title": "5 comandos do DeepSeek que todo mundo deveria conhecer",
    "image": "https://s2-techtudo.glbimg.com/5yEEwXXe39b8Bw5_jXOAotNxy8g=/0x0:1622x1080/888x0/smart/filters:strip_icc()/i.s3.glbimg.com/v1/AUTH_08fbf48bc0524877943fe86e43087e7a/internal_photos/bs/2025/G/o/oxNc4fReezt5omai2EKw/design-sem-nome-9-1-.jpg",
    "message": "Concorrente do ChatGPT pode atender comandos simples e complexos; a seguir, veja como estruturar prompts para testar no chatbot de inteligência artificial chinês\r\n\r\nA DeepSeek possui um chatbot de inteligência artificial (IA) que ainda é novo para o público, mas tem sido eficiente na entrega de resultados, desde tarefas simples, como traduzir textos, a comandos mais complexos, como a geração de códigos. Desde o seu lançamento para o público, o modelo mais avançado da empresa chinesa, o LLM DeepSeek-R1, tem se destacado por superar o GPT-4 o1, da OpenAI e com custo de operação menores que seus concorrentes. O aplicativo de chatbot se tornou o mais baixado na App Store dos EUA, e na Google Play Store já conta com mais de 10 milhões de downloads ao redor do mundo. \r\n\r\nVale lembrar que, atualmente, a linha de raciocínio do chatbot (Deep Think) aparece somente em inglês, mas é possível escrever comandos e conferir a resposta em português. A seguir, veja quais comandos todo usuário deve testar no DeepSeek e como estruturar prompts.\r\n\r\n 1. Resumo de textos longos\r\n\r\n O primeiro comando da lista para testar no DeepSeek é o resumo de textos. Com exceção do raciocínio lógico sendo apresentado no chatbot chinês, é possível aplicar o prompt em outras plataformas de IA. Em nosso teste, foi proposto para que a IA resumisse um artigo jornalístico sobre o Oscar 2025, com mais de 9 mil caracteres, em apenas um parágrafo. Nas primeiras tentativas, o chatbot sinalizou que o servidor estava ocupado e, depois, que ainda 'não tinha capacidade para responder' o prompt. \r\n\r\nMinutos depois, mais uma tentativa foi feita e, com o botão 'Deep Think' ativado, a inteligência artificial gerou a resposta em oito segundos, com um resumo conciso sobre o artigo. O prompt utilizado foi: 'Faça um resumo do artigo jornalístico abaixo em apenas um parágrafo: [cole o texto]'. Vale ressaltar que, o próprio chatbot apresenta o tempo utilizado para responder ao prompt. \r\n\r\n 2. Geração de texto criativo\r\n\r\nPara os usuários que buscam inspirações na produção de textos criativos, como poemas, histórias ou slogan de uma marca, a plataforma do DeepSeek é uma opção. No teste, foi pedido para o chatbot gerar opções de textos criativos com o tema de aniversário. É importante que o comando escrito forneça o máximo de detalhes possíveis, assim há mais probabilidade da IA fornecer respostas assertivas. O prompt utilizado no teste foi: 'Crie três opções de textos criativos, com até 200 palavras, com o tema de aniversário para uma pessoa do gênero feminino que vai fazer 22 anos'. Em apenas 22 segundos, a plataforma gerou as respostas.\r\n\r\n 3. Tradução multilíngue\r\n\r\nExistem diversas plataformas que fazem a tradução multilíngue, mas é possível também testar a função com a inteligência artificial do DeepSeek. No chatbot foi utilizado um trecho do livro 'É Assim Que Acaba' com o prompt 'Traduza o seguinte texto para o francês: [cole o texto]'. A inteligência artificial precisou de 35 segundos para mostrar a tradução e listar como algumas frases foram adaptadas para o francês, respeitando as regras gramaticais do idioma europeu. \r\n\r\n 4. Resolução de problemas matemáticos\r\n\r\nA principal característica de um prompt eficiente está nos detalhes descritos, e para resolver problemas matemáticos esse é um fator primordial. Para questões ou fórmulas complexas, vale ressaltar no comando para que a IA 'pense em voz alta'. Por exemplo, em nosso teste utilizamos o seguinte prompt: 'Um vestido custa R$ 50 após um desconto de 30%. Qual é o preço original? Explique o passo a passo'. \r\n\r\nAlém de expor o raciocínio lógico, a IA do DeepSeek separou a resolução do problema em três fases, o que é o modo de 'pensar em voz alta', trazendo o maior número de detalhes da resolução. Em seguida, foi exibida a resposta final. \r\n\r\n 5. Geração de código\r\n\r\nSegundo a Apidog, plataforma de desenvolvimento de API, para que a inteligência artificial da DeepSeek seja uma assistente de codificação eficiente, é importante estruturar prompts efetivos. Ao escrever um comando no chatbot, foi proposto que a IA resolvesse uma tarefa simples a partir da linguagem de programação Python. \r\n\r\nO prompt utilizado foi: 'Escreva um código em python que exibe a frase 'TechTudo, o maior portal de tecnologia do Brasil'. A versão python é 3.1'. Seu raciocínio lógico precisou de 17 segundos para exibir a resposta e um breve comparativo de algumas versões da linguagem Python. \r\n\r\nFonte: https://www.techtudo.com.br/listas/2025/02/5-comandos-do-deepseek-que-todo-mundo-deveria-conhecer-edsoftwares.ghtml",
    "createdAt": "2025-02-06T09:53:21.000Z",
    "updatedAt": "2025-02-06T09:53:21.000Z"
  },
  {
    "id": 9,
    "data": "2025-02-07T05:53:21.000Z",
    "title": "EUA planejam proibir IA DeepSeek em dispositivos oficiais do governo",
    "image": "https://tm.ibxk.com.br/2025/02/06/06204854965111.jpg?ims=1280x480",
    "message": "O uso da inteligência artificial DeepSeek em celulares e outros dispositivos do governo dos Estados Unidos pode ser proibido em breve, assim como aconteceu na Austrália esta semana. Uma proposta de banimento da tecnologia em gadgets oficiais deve ser apresentada por membros do Congresso nesta sexta-feira (7).\r\n\r\n A decisão é baseada na investigação feita por pesquisadores da Feroot Security que levantou preocupações quanto à segurança da IA generativa. Os especialistas disseram ter identificado um código dentro da versão web do bot capaz de enviar dados do usuário para a China Mobile, estatal de telecomunicações do país asiático.\r\n\r\n “Nossas informações pessoais são enviadas para a China, não há negação, e a ferramenta DeepSeek coleta tudo que usuários americanos conectam a ela”, declarou o analista Ivan Tsarynny, que participou do trabalho, em entrevista ao The Wall Street Journal. A análise foi revisada por outros especialistas em segurança cibernética norte-americanos.\r\n\r\n O bloqueio ao DeepSeek já aconteceu em dispositivos de funcionários da NASA e da Marinha dos EUA, assim como nos smartphones disponibilizados pelo governo do Texas aos seus contratados. Globalmente, a IA chinesa está banida em dispositivos de funcionários dos governos da Coreia do Sul e da Itália, além da Austrália.\r\n\r\n Riscos à segurança nacional\r\n\r\n Na proposta que deve chegar ao Congresso americano, o democrata Josh Gottheimer e o republicano Darin LaHood alegam que o DeepSeek representa uma “ameaça à segurança nacional” dos EUA devido à coleta e compartilhamento de dados com a China. O projeto é semelhante ao que defende a proibição do TikTok no país — vale notar ainda que, a preocupação dos EUA com dados gerenciados por chineses também causou o banimento da Huawei.\r\n\r\n Segundo Gottheimer, o uso do bot em dispositivos do governo norte-americano pode colocar a administração chinesa em contato direto com dados oficiais sigilosos. Em caso de aprovação da iniciativa, outros apps desenvolvidos pela startup chinesa também devem ser proibidos.\r\n\r\n Contando com um modelo de IA avançado e supostamente mais barato que os rivais, o DeepSeek colocou o domínio dos chatbots americanos à prova. Na semana passada, o app chegou a ser o mais baixado nos EUA, superando o ChatGPT.\r\n\r\nFonte: https://www.tecmundo.com.br/seguranca/402333-eua-planejam-proibir-ia-deepseek-em-dispositivos-oficiais-do-governo.htm",
    "createdAt": "2025-02-07T05:53:21.000Z",
    "updatedAt": "2025-02-07T05:53:21.000Z"
  },
  {
    "id": 10,
    "data": "2025-02-07T10:00:21.000Z",
    "title": "Elon Musk VS Sam Altman - The BRIE",
    "image": "https://tm.ibxk.com.br/2025/02/06/06190824868038.jpg?ims=1280x480",
    "message": "O embate judicial entre Elon Musk e Sam Altman sobre o futuro da OpenAI promete se arrastar até pelo menos 2027, segundo a juíza responsável pelo caso. Musk acusa Altman de trair o propósito original da empresa, que ele ajudou a fundar em 2015, ao transformá-la em um negócio lucrativo em parceria com a Microsoft. Ele também aponta supostas práticas anticompetitivas para bloquear investimentos na rival xAI.\r\n\r\n A juíza Gonzalez Rogers negou um pedido imediato de Musk para barrar a conversão da OpenAI em empresa lucrativa, mas considerou plausível a alegação de que ele havia feito doações sob a condição de que a OpenAI permaneceria sem fins lucrativos. A disputa se intensificou com o lançamento do megaprojeto Stargate, parceria entre OpenAI, Oracle e SoftBank que promete injetar US$ 500 bilhões em infraestrutura de IA nos EUA.\r\n\r\n Musk atacou o projeto no X, insinuando que o dinheiro não existia, enquanto Altman rebateu, dizendo que Musk deveria “colocar os EUA em primeiro lugar”. A rivalidade cresceu desde que Musk deixou a OpenAI em 2018 e criou a xAI, mas agora a disputa vai além da briga pessoal: envolve o domínio do setor de IA e o controle sobre bilhões de dólares em investimentos. A juíza também questionou a relação entre OpenAI e Microsoft, que já investiu US$ 13,75 bilhões na startup, mas tenta se apresentar como concorrente no mercado de chatbots.\r\n\r\nFonte: https://www.techtudo.com.br/listas/2025/02/5-comandos-do-deepseek-que-todo-mundo-deveria-conhecer-edsoftwares.ghtml",
    "createdAt": "2025-02-07T10:00:21.000Z",
    "updatedAt": "2025-02-07T10:00:21.000Z"
  },
  {
    "id": 12,
    "data": "2025-02-07T15:53:21.000Z",
    "title": "IAs que pensam demais podem ser um problema para o mundo: o Overthinking",
    "image": "https://tm.ibxk.com.br/2025/02/07/07134315930511.jpg?ims=1280x480",
    "message": "Os grandes modelos de linguagem (LLMs) como o o1, da OpenAI, representam avanços significativos em desempenho, mas ainda estão longe de atingir a eficiência ideal. Pesquisadores da Tencent AI Lab e da Shanghai Jiao Tong University publicaram o primeiro estudo abrangente sobre um problema recorrente nesses modelos que buscam imitar o raciocínio humano: o overthinking (ou “reflexão excessiva”, em português).\r\n\r\n O estudo analisa as causas e possíveis soluções para o uso excessivo de tokens, consumo elevado de poder computacional e desperdício de recursos no processamento de outputs de modelos generativos como o o1 e o DeepSeek R1, seu concorrente chinês de nível similar. Essas inteligências artificiais tentam simular o processo cognitivo humano para formular respostas em uma abordagem conhecida como Chain of Thought (CoT, ou “Cadeia de pensamentos” em português). No entanto, esse método pode consumir até 1.953% mais tokens do que IAs menos potentes — muitas vezes, sem necessidade.\r\n\r\n No artigo, os pesquisadores ilustram o fenômeno com uma pergunta simples: quanto é 2 + 3? O teste foi aplicado a diversos LLMs populares, como GPT-4o, Gemini Pro e Claude-3.5, e comparado ao QwQ-32B-Preview, um modelo racional da Qwen Team.\r\n\r\n Os resultados revelam um contraste marcante:\r\n\r\n Os LLMs tradicionais forneceram respostas corretas consumindo menos de 10 tokens (exceto o Qwen2.5-Math-72B, que usou quase 50 tokens);\r\n\r\n O QwQ-32B-Preview utilizou 901 tokens para responder à mesma pergunta.\r\n\r\n O modelo racional da Qwen Team elaborou 10 soluções diferentes, todas chegando à mesma conclusão: 2 + 3 = 5. Ele conseguiu alcançar o resultado correto na primeira tentativa.\r\n\r\n Embora a pergunta seja simples, o QwQ-32B-Preview não consegue diferenciá-la de inputs mais complexos. Por isso, a IA reflete sobre o problema até concluir que não há outra alternativa possível, mesmo que a primeira solução já estivesse correta com apenas 39 tokens.\r\n\r\n “No exemplo da figura, observamos que a rodada inicial de soluções já apresenta a resposta correta. As soluções posteriores, que compõem a maioria dos tokens gerados, não aumentam a precisão”, destaca o estudo.\r\n\r\n Após testes, os pesquisadores identificaram que, em 92% dos cenários, as IAs chegaram à resposta correta logo na primeira tentativa. O problema do overthinking foi mais recorrente em questões matemáticas mais simples.\r\n\r\n Por que overthinking de IA é um problema?\r\n\r\n As inteligências artificiais generativas demandam um poder computacional significativo para se manterem ativas. O aumento da necessidade de processamento impacta diretamente o consumo de energia e o uso de componentes embarcados em data centers. Esse é um problema especial para empresas com plataformas centralizadas, como OpenAI, DeepSeek e Google, que precisam expandir continuamente seus servidores para atender à crescente demanda dos usuários.\r\n\r\n Para o usuário, o maior problema é o consumo da janela de contexto. A técnica de cadeia de pensamentos utiliza muito mais tokens do que o normal, e esses tokens contam para a janela de contexto — o espaço onde a pergunta é inserida, por exemplo. Embora isso não faça grande diferença para prompts simples, pode impactar significativamente solicitações mais complexas.\r\n\r\n Overthinking só é um problema quando é em vão\r\n\r\n Apesar disso, a implementação da técnica de CoT em modelos de linguagem avançados representa um avanço crucial. A capacidade desses modelos de documentar sua linha de raciocínio ao gerar respostas é extremamente útil para o próprio treinamento da IA e o desenvolvimento de modelos destilados, destaca Billy Garcia, pesquisador de inteligência artificial e cofundador da Abstrakt Gen-AI, em entrevista ao TecMundo.\r\n\r\n “Basicamente, a perda de eficiência de 1.953% só ocorre quando o modelo é escolhido de forma inadequada”, explica Garcia. “No entanto, ter acesso a essa cadeia de raciocínio é essencial para determinados casos de uso — principalmente em pesquisas.”\r\n\r\n “Portanto, usuários não devem recorrer a modelos avançados para responder perguntas triviais, como “Quanto é 2 + 3?”, ressalta o especialista.\r\n\r\n Existe solução para o overthinking de IA?\r\n\r\n O artigo explora diferentes estratégias para reduzir a reflexão excessiva e tornar o processamento de modelos racionais mais eficiente. As soluções incluem métodos de treinamento otimizados, como o chamado “self-training”, que usam amostras de conjunto de dados gerados pela IA para treinar e aperfeiçoar a própria IA.\r\n\r\n “O self-training acontece através de diferentes métodos de refinamento e tem o objetivo de tornar o modelo mais eficiente sem sacrificar a precisão para tarefas mais complexas”, descreveu Garcia. Basicamente, é como preparar o modelo para “pensar menos”.\r\n\r\n Entre as abordagens sugeridas estão:\r\n\r\n Refinamento supervisionado: aprimoramento de modelos com base em dados sintéticos positivos;\r\n\r\n Otimização de preferência direta: treinamento dos modelos considerando a resposta preferida pelos humanos;\r\n\r\n Otimização de preferência de raciocínio: adição de registros negativos de raciocínio para evitar repetições desnecessárias;\r\n\r\n Otimização de preferência simples: ajuste fino para alinhar a função de recompensa à métrica de geração de respostas.\r\n\r\n No entanto, sozinhas, essas soluções não eliminam completamente o overthinking. “Embora respostas amostrais mais curtas melhorem a eficiência de modelos do tipo o1, eles ainda sofrem com reflexão excessiva”, explica o estudo.\r\n\r\n Por isso, o artigo propõe métodos complementares para identificar quando a IA já obteve a resposta correta, como:\r\n\r\n Primeira Solução Correta (FCS, em inglês): define a primeira resposta gerada como a correta;\r\n\r\n FCS + Reflexão: permite que a IA reflita apenas sobre a precisão da primeira resposta, garantindo um resultado mais confiável na segunda tentativa;\r\n\r\n Soluções avidamente diversas: adiciona novas estratégias de reflexão, caso os outputs anteriores não sejam consistentes.\r\n\r\n \r\n\r\n Ao combinar essas estratégias, os pesquisadores observaram uma redução significativa no consumo de tokens e na demanda computacional, sem comprometer a capacidade cognitiva da IA racional em relação aos LLMs tradicionais.\r\n\r\n Todo mundo precisa de uma IA racional?\r\n\r\n O o1 e o DeepSeek-R1 representam avanços notáveis no desenvolvimento de inteligência artificial generativa, mas suas aplicações não são tão relevantes para o uso cotidiano. “A complexidade desses modelos é mais adequada para problemas que exigem raciocínio profundo, como pesquisas científicas ou tomada de decisões complexas”, explica Garcia.\r\n\r\n No dia a dia, em tarefas como desenvolvimento de softwares simples, revisão de textos curtos e outras aplicações triviais, é provável que tokens sejam consumidos desnecessariamente.\r\n\r\n Atualmente, o o1 da OpenAI está disponível na assinatura ChatGPT Plus com “acesso limitado”. Durante sua fase de prévia, o modelo oferecia uma janela de contexto de até 128 mil tokens, distribuídos entre as versões o1-preview (32 mil tokens) e o1-mini (65 mil tokens).\r\n\r\n Sendo assim, ao recorrer à ajuda de uma inteligência artificial, é importante escolher bem qual modelo utilizar. Isso pode ajudar não só a ter respostas mais rapidamente, como também economizar tokens que podem ser úteis em uma consulta posterior.\r\n\r\nFonte: https://www.tecmundo.com.br/software/402356-ias-que-pensam-demais-podem-ser-um-problema-para-o-mundo-o-overthinking.htm",
    "createdAt": "2025-02-07T15:53:21.000Z",
    "updatedAt": "2025-02-07T15:53:21.000Z"
  },
  {
    "id": 13,
    "data": "2025-02-05T15:53:21.000Z",
    "title": "Como o nosso cérebro processa tempo e espaço?",
    "image": "https://tm.ibxk.com.br/2025/02/07/07101638774061.jpg?ims=1280x480",
    "message": "Conseguir discriminar tempo e espaço é uma habilidade excelente do nosso cérebro, afinal, quem nunca precisou desviar de um chinelo voador atirado pela mãe em represália à última obra de arte?  \r\n\r\n Mesmo sem puxar uma calculadora do bolso, você consegue calcular o tempo que o chinelo levaria para atingir você e em que direção você deve correr para não ser atingido.\r\n\r\n Essa mesma habilidade pode ser generalizada para diversas atividades cotidianas, como lavar a louça, atravessar uma rua ou ainda comer, realizando a tarefa dentro do tempo estimado de intervalo, assim como localizar o prato onde repousar novamente o talher.\r\n\r\n Mas como exatamente nosso cérebro consegue organizar e processar essas informações em escala funcional? Talvez, a resposta tenha começado a ser descoberta. Confira!\r\n\r\n Localizado em tempo espaço\r\n\r\n Nosso cérebro é capaz de receber diversos estímulos sensoriais que irão nos informar, conscientemente, onde nosso corpo está e em que tempo ele permaneceu ou precisará permanecer na mesma posição.\r\n\r\n Perceptualmente, nós conseguimos extrapolar essa habilidade para o ambiente em que vivemos, sabendo, por exemplo, quanto tempo um semáforo leva para abrir após começar a piscar a luz vermelha para pedestres e as chances que você tem de atravessar ainda nesse intervalo.  \r\n\r\n O tempo de reação, consideração do espaço a ser percorrido e do meio em sua volta podem ser relativos, levando a decisões pessoais sobre atravessar ou não, contudo, a medida de tempo e espaço pode ser igual para todas as pessoas, desde que não haja doenças ou danos neurológicos associados, graças como o cérebro processa essas informações em um nível funcional.\r\n\r\n Um novo estudo publicado na Revista Nature Communications apresenta as reações desencadeadas no nosso cérebro em situações em que precisamos discriminar o tempo de duração e o espaço em que os fenômenos ocorrem de uma maneira neurofuncional.\r\n\r\n Segundo a pesquisa, realizada com 13 participantes sem disfunções cognitivas ou danos neurológicos, o processamento do tempo e espaço começam no córtex visual, na parte posterior do cérebro.\r\n\r\n Nessa região, ambas as informações são processadas pelo mesmo grupo de neurônios, não havendo distinção. Segundo os dados de ressonância magnética funcional, essa região permanecerá mais ativada quanto maior o tempo de exposição ao estímulo. Desse modo, o tempo e espaço fazem parte do mesmo componente a ser processado pelo cérebro.\r\n\r\n Contudo, a informação neuronal ‘caminha’ para regiões anteriores do cérebro, como nos lobos parietais e fronto-temporais. Conforme a ativação de outras regiões avança, começa a surgir diferenciação nos grupos neurais que identificam e reconhecem as informações espaciais e temporais. \r\n\r\n Nessas áreas há uma seletividade do cérebro que irá sofrer ativações em diferentes períodos de exposição ao estímulo, além disso, os grupos neuronais parecem se especializar ao longo do trajeto da informação, ocasionando em uma separação no modo como há o reconhecimento temporal e espacial. \r\n\r\n Se pensarmos no cérebro como um escritório e na trilha que a informação irá percorrer, seria como se a papelada espaço temporal chegasse e fosse entregue em uma salinha dos fundos, onde toda a documentação é processada por uma só equipe.\r\n\r\n Em seguida, ela seria levada a uma sala intermediária, onde os documentos começam a ser separados em ordem de entrada sensorial e temporal, podendo ainda estar um pouco misturados, com equipes trabalhando em conjunto, na repartição parietal.\r\n\r\n Logo após, a informação passa pelo centro de ‘preparação motora’, região do cérebro que nos prepara para realizar os movimentos, com informações e equipes já separadas, que avaliam o tempo e espaço individualmente. Por fim, toda documentação classificada e preparada por equipes neurais especializadas entregam os dados para a área responsável pelo planejamento, julgamento e ação, o lobo frontal.\r\n\r\n Graças a essa diferenciação nos mecanismos de reconhecimento do tempo e espaço, somos capazes de realizar diferentes tarefas, desempenhando cada função no intervalo certo de tempo, sem nos assustarmos com cada objeto que se aproxima. \r\n\r\n Ainda que a amostra do estudo seja pequena, a pesquisa e os dados conferem bons indícios para estudos mais focados no campo das doenças neurodegenerativas ou mesmo crônicas, como o acidente vascular cerebral, visto que nesses casos, esse trajeto informacional pode ser prejudicado, gerando déficits de reconhecimento e ação temporal e espacial. \r\n\r\n Um exemplo desse tipo de efeito, são as dismetrias, onde pacientes com danos neurológicos têm dificuldade em controlar o movimento dos membros superiores, ou inferiores, pois não conseguem ‘julgar’ a velocidade do movimento e a distância dos objetos ou do solo, errando o alvo.\r\n\r\n Estudos como esse, desenvolvido pela SISSA (Scuola Internazionale di Studi Avanzati) dão arcabouço para novas investigações, pois com o mapa das regiões cerebrais e suas funções, as terapias podem ser mais especializadas, contribuindo para o avanço de técnicas em reabilitação e manutenção de funções cognitivas, motoras, incluindo tratamentos em disfunções mentais que geram desorientação.\r\n\r\n Percebendo o mundo\r\n\r\n Nesse estudo, o grupo destacou as funções e mecanismos cerebrais que contribuem para o processamento da informação sobre o tempo e espaço, não relatando o papel da percepção.  \r\n\r\n Nosso cérebro é um mix de biologia, química e física com um toque de consciência que ainda não sabemos exatamente onde surge, mesmo que hajam estudos diversos tentando descrever onde nasce a individualidade de cada ser nesse planeta.\r\n\r\n Desse modo, compreender a arquitetura e circuitos elétricos que regem a funcionalidade do ser humano é tão importante, pois se a corrente não está chegando no estágio final, podemos mapear onde houve um rompimento e quais as possibilidade de realizar uma reforma. Quem dera fosse fácil assim. \r\n\r\n E você, orientado em tempo e espaço? Então nos conte em nossas redes sociais qual a função cerebral você acha mais fantástica, e para dar uma dica, nosso cérebro é capaz de criar sua própria novela diária para nos ajudar a nos orientar no tempo! \r\n\r\n Fonte: https://www.tecmundo.com.br/ciencia/402271-como-o-nosso-cerebro-processa-tempo-e-espaco.htm",
    "createdAt": "2025-02-05T15:53:21.000Z",
    "updatedAt": "2025-02-05T15:53:21.000Z"
  }
]
